#!/usr/bin/env python3
"""
TensorFlowå¤šçº¿ç¨‹æ¨ç†æ€§èƒ½æµ‹è¯•

å¯¹æ¯”ä¸åŒçº¿ç¨‹é…ç½®å¯¹æ¨ç†æ€§èƒ½çš„å½±å“
æµ‹è¯•BERT-Baseå’ŒMobileNetä¸¤ä¸ªæ¨¡å‹
"""

import os
import sys
import time
import json
import argparse
import subprocess
from pathlib import Path
import multiprocessing

def print_section(title):
    print("\n" + "=" * 70)
    print(title)
    print("=" * 70)

def get_cpu_info():
    """è·å–CPUæ ¸å¿ƒæ•°ä¿¡æ¯"""
    physical_cores = multiprocessing.cpu_count()

    # å°è¯•è·å–ç‰©ç†æ ¸å¿ƒæ•°ï¼ˆLinuxï¼‰
    try:
        with open('/proc/cpuinfo', 'r') as f:
            cpuinfo = f.read()
            # ç»Ÿè®¡ç‰©ç†CPU IDæ•°é‡
            physical_ids = set()
            for line in cpuinfo.split('\n'):
                if line.startswith('physical id'):
                    physical_ids.add(line.split(':')[1].strip())

            # ç»Ÿè®¡æ¯ä¸ªç‰©ç†CPUçš„æ ¸å¿ƒæ•°
            cores_per_cpu = 0
            for line in cpuinfo.split('\n'):
                if line.startswith('cpu cores'):
                    cores_per_cpu = int(line.split(':')[1].strip())
                    break

            actual_physical_cores = len(physical_ids) * cores_per_cpu if physical_ids else physical_cores
    except:
        actual_physical_cores = physical_cores

    return {
        'logical_cores': physical_cores,
        'physical_cores': actual_physical_cores,
        'hyperthreading': physical_cores > actual_physical_cores
    }

def run_benchmark_worker(intra_threads, inter_threads, model_type, num_runs, batch_size):
    """è°ƒç”¨workerè„šæœ¬æ‰§è¡Œbenchmark"""
    script_path = Path(__file__).parent / "benchmark_threading_worker.py"

    cmd = [
        "python3",
        str(script_path),
        str(intra_threads),
        str(inter_threads),
        model_type,
        str(num_runs),
        str(batch_size)
    ]

    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=300,  # 5åˆ†é’Ÿè¶…æ—¶
            check=True
        )

        # è§£æJSONè¾“å‡º
        return json.loads(result.stdout.strip().split('\n')[-1])
    except subprocess.CalledProcessError as e:
        print(f"  âŒ æµ‹è¯•å¤±è´¥:")
        print(f"     Error: {e}")
        if e.stderr:
            print(f"     Stderr: {e.stderr[:500]}")
        return None
    except json.JSONDecodeError as e:
        print(f"  âŒ JSONè§£æå¤±è´¥:")
        print(f"     Error: {e}")
        print(f"     Output: {result.stdout[:500]}")
        return None
    except Exception as e:
        print(f"  âŒ æ„å¤–é”™è¯¯: {e}")
        return None

def test_threading_configs(model_type, model_name, cpu_info, num_runs=30, batch_size=1):
    """æµ‹è¯•å¤šç§çº¿ç¨‹é…ç½®"""
    print_section(f"æµ‹è¯• {model_name} - ä¸åŒçº¿ç¨‹é…ç½®")

    logical_cores = cpu_info['logical_cores']
    physical_cores = cpu_info['physical_cores']

    print(f"CPUä¿¡æ¯:")
    print(f"  é€»è¾‘æ ¸å¿ƒæ•°: {logical_cores}")
    print(f"  ç‰©ç†æ ¸å¿ƒæ•°: {physical_cores}")
    print(f"  è¶…çº¿ç¨‹: {'å¯ç”¨' if cpu_info['hyperthreading'] else 'ç¦ç”¨'}")

    # æµ‹è¯•é…ç½®åˆ—è¡¨
    # (intra_threads, inter_threads, description)
    test_configs = [
        (1, 1, "å•çº¿ç¨‹"),
        (2, 1, "2çº¿ç¨‹ (intra)"),
        (4, 1, "4çº¿ç¨‹ (intra)"),
        (8, 1, "8çº¿ç¨‹ (intra)"),
        (physical_cores, 1, f"{physical_cores}çº¿ç¨‹ (ç‰©ç†æ ¸å¿ƒ)"),
        (physical_cores, 2, f"{physical_cores}çº¿ç¨‹ + 2 inter"),
        (0, 0, "è‡ªåŠ¨é…ç½®"),
    ]

    results = []

    for intra, inter, desc in test_configs:
        print(f"\næµ‹è¯•é…ç½®: {desc}")
        print(f"  intra_op_parallelism_threads: {intra if intra > 0 else 'auto'}")
        print(f"  inter_op_parallelism_threads: {inter if inter > 0 else 'auto'}")

        result = run_benchmark_worker(intra, inter, model_type, num_runs, batch_size)

        if result:
            result['description'] = desc
            results.append(result)

            print(f"  âœ“ å¹³å‡å»¶è¿Ÿ: {result['mean_ms']:.2f} ms")
            print(f"  âœ“ ååé‡: {result['throughput_samples_per_sec']:.2f} samples/sec")
        else:
            print(f"  âš ï¸  è·³è¿‡æ­¤é…ç½®")

    return results

def find_optimal_config(results):
    """æ‰¾åˆ°æœ€ä¼˜é…ç½®"""
    if not results:
        return None
    # æŒ‰ååé‡æ’åº
    sorted_results = sorted(results, key=lambda x: x['throughput_samples_per_sec'], reverse=True)
    return sorted_results[0]

def generate_report(bert_results, mobilenet_results, cpu_info, output_file):
    """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
    print_section("ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š")

    # æ‰¾åˆ°æœ€ä¼˜é…ç½®
    bert_optimal = find_optimal_config(bert_results)
    mobilenet_optimal = find_optimal_config(mobilenet_results)

    if not bert_optimal or not mobilenet_optimal:
        print("âš ï¸ ç¼ºå°‘æµ‹è¯•ç»“æœï¼Œæ— æ³•ç”Ÿæˆå®Œæ•´æŠ¥å‘Š")
        return

    # è®¡ç®—ç›¸å¯¹å•çº¿ç¨‹çš„åŠ é€Ÿæ¯”
    bert_baseline = next((r for r in bert_results if r['intra_threads'] == 1), None)
    mobilenet_baseline = next((r for r in mobilenet_results if r['intra_threads'] == 1), None)

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# TensorFlowå¤šçº¿ç¨‹æ¨ç†æ€§èƒ½æµ‹è¯•æŠ¥å‘Š\n\n")
        f.write(f"**æµ‹è¯•æ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")

        f.write("## ç³»ç»Ÿä¿¡æ¯\n\n")
        f.write(f"- CPUé€»è¾‘æ ¸å¿ƒæ•°: {cpu_info['logical_cores']}\n")
        f.write(f"- CPUç‰©ç†æ ¸å¿ƒæ•°: {cpu_info['physical_cores']}\n")
        f.write(f"- è¶…çº¿ç¨‹: {'å¯ç”¨' if cpu_info['hyperthreading'] else 'ç¦ç”¨'}\n\n")

        # BERT-Baseç»“æœ
        f.write("## BERT-Base çº¿ç¨‹é…ç½®æµ‹è¯•\n\n")
        f.write("| é…ç½® | Intraçº¿ç¨‹ | Interçº¿ç¨‹ | å¹³å‡å»¶è¿Ÿ | P95å»¶è¿Ÿ | ååé‡ | vså•çº¿ç¨‹ |\n")
        f.write("|------|-----------|-----------|----------|---------|--------|----------|\n")

        for result in bert_results:
            if bert_baseline:
                speedup = result['throughput_samples_per_sec'] / bert_baseline['throughput_samples_per_sec']
            else:
                speedup = 1.0

            intra_str = str(result['intra_threads']) if result['intra_threads'] > 0 else 'auto'
            inter_str = str(result['inter_threads']) if result['inter_threads'] > 0 else 'auto'

            f.write(f"| {result['description']} | {intra_str} | {inter_str} | ")
            f.write(f"{result['mean_ms']:.2f} ms | {result['p95_ms']:.2f} ms | ")
            f.write(f"{result['throughput_samples_per_sec']:.2f} samples/s | ")
            f.write(f"{speedup:.2f}x {'ğŸš€' if speedup > 1.5 else ''} |\n")

        f.write(f"\n**æœ€ä¼˜é…ç½®**: {bert_optimal['description']}\n")
        f.write(f"- ååé‡: {bert_optimal['throughput_samples_per_sec']:.2f} samples/sec\n")
        if bert_baseline:
            f.write(f"- ç›¸å¯¹å•çº¿ç¨‹åŠ é€Ÿ: {bert_optimal['throughput_samples_per_sec'] / bert_baseline['throughput_samples_per_sec']:.2f}x\n\n")

        # MobileNetç»“æœ
        f.write("## MobileNetV2 çº¿ç¨‹é…ç½®æµ‹è¯•\n\n")
        f.write("| é…ç½® | Intraçº¿ç¨‹ | Interçº¿ç¨‹ | å¹³å‡å»¶è¿Ÿ | P95å»¶è¿Ÿ | ååé‡ | vså•çº¿ç¨‹ |\n")
        f.write("|------|-----------|-----------|----------|---------|--------|----------|\n")

        for result in mobilenet_results:
            if mobilenet_baseline:
                speedup = result['throughput_samples_per_sec'] / mobilenet_baseline['throughput_samples_per_sec']
            else:
                speedup = 1.0

            intra_str = str(result['intra_threads']) if result['intra_threads'] > 0 else 'auto'
            inter_str = str(result['inter_threads']) if result['inter_threads'] > 0 else 'auto'

            f.write(f"| {result['description']} | {intra_str} | {inter_str} | ")
            f.write(f"{result['mean_ms']:.2f} ms | {result['p95_ms']:.2f} ms | ")
            f.write(f"{result['throughput_samples_per_sec']:.2f} samples/s | ")
            f.write(f"{speedup:.2f}x {'ğŸš€' if speedup > 1.5 else ''} |\n")

        f.write(f"\n**æœ€ä¼˜é…ç½®**: {mobilenet_optimal['description']}\n")
        f.write(f"- ååé‡: {mobilenet_optimal['throughput_samples_per_sec']:.2f} samples/sec\n")
        if mobilenet_baseline:
            f.write(f"- ç›¸å¯¹å•çº¿ç¨‹åŠ é€Ÿ: {mobilenet_optimal['throughput_samples_per_sec'] / mobilenet_baseline['throughput_samples_per_sec']:.2f}x\n\n")

        # æ€»ç»“
        f.write("## æ€»ç»“\n\n")

        f.write("### æ€§èƒ½æå‡\n\n")
        if bert_baseline and mobilenet_baseline:
            bert_speedup = bert_optimal['throughput_samples_per_sec'] / bert_baseline['throughput_samples_per_sec']
            mobilenet_speedup = mobilenet_optimal['throughput_samples_per_sec'] / mobilenet_baseline['throughput_samples_per_sec']

            f.write(f"- **BERT-Base**: {bert_speedup:.2f}x åŠ é€Ÿ (å•çº¿ç¨‹ â†’ {bert_optimal['description']})\n")
            f.write(f"- **MobileNetV2**: {mobilenet_speedup:.2f}x åŠ é€Ÿ (å•çº¿ç¨‹ â†’ {mobilenet_optimal['description']})\n\n")

        f.write("### æ¨èé…ç½®\n\n")
        f.write(f"**BERT-Baseæ¨è**:\n")
        f.write(f"```python\n")
        f.write(f"tf.config.threading.set_intra_op_parallelism_threads({bert_optimal['intra_threads']})\n")
        f.write(f"tf.config.threading.set_inter_op_parallelism_threads({bert_optimal['inter_threads']})\n")
        f.write(f"```\n\n")

        f.write(f"**MobileNetV2æ¨è**:\n")
        f.write(f"```python\n")
        f.write(f"tf.config.threading.set_intra_op_parallelism_threads({mobilenet_optimal['intra_threads']})\n")
        f.write(f"tf.config.threading.set_inter_op_parallelism_threads({mobilenet_optimal['inter_threads']})\n")
        f.write(f"```\n\n")

        f.write("### ä½¿ç”¨å»ºè®®\n\n")
        f.write("1. **ç”Ÿäº§éƒ¨ç½²**: æ ¹æ®CPUæ ¸å¿ƒæ•°å’Œå¹¶å‘éœ€æ±‚è°ƒæ•´çº¿ç¨‹é…ç½®\n")
        f.write("2. **å•å®ä¾‹é«˜åå**: ä½¿ç”¨ç‰©ç†æ ¸å¿ƒæ•°ä½œä¸ºintra_threads\n")
        f.write("3. **å¤šå®ä¾‹å¹¶å‘**: é™åˆ¶æ¯ä¸ªå®ä¾‹çš„çº¿ç¨‹æ•°ï¼Œé¿å…èµ„æºç«äº‰\n")
        f.write("4. **å®æ—¶æ¨ç†**: ä½¿ç”¨è¾ƒå°‘çº¿ç¨‹æ•°å‡å°‘å»¶è¿ŸæŠ–åŠ¨\n\n")

        f.write("## å‚è€ƒ\n\n")
        f.write("- [TensorFlowçº¿ç¨‹é…ç½®æ–‡æ¡£](https://www.tensorflow.org/api_docs/python/tf/config/threading)\n")
        f.write("- [CPUä¼˜åŒ–å®Œæ•´æŒ‡å—](TENSORFLOW_CPU_OPTIMIZATION.md)\n")
        f.write("- [ç»¼åˆBenchmarkç»“æœ](BENCHMARK_RESULTS.md)\n")

    print(f"âœ“ æŠ¥å‘Šå·²ä¿å­˜: {output_file}")

def main():
    parser = argparse.ArgumentParser(description="TensorFlowå¤šçº¿ç¨‹æ¨ç†æ€§èƒ½æµ‹è¯•")
    parser.add_argument("--output-dir", default="results/threading_benchmark",
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--num-runs", type=int, default=30,
                       help="æ¯ä¸ªé…ç½®çš„æµ‹è¯•è¿­ä»£æ¬¡æ•°")
    parser.add_argument("--batch-size", type=int, default=1,
                       help="æ‰¹æ¬¡å¤§å°")
    args = parser.parse_args()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    print_section("TensorFlowå¤šçº¿ç¨‹æ¨ç†æ€§èƒ½æµ‹è¯•")
    print(f"æµ‹è¯•é…ç½®:")
    print(f"  æ¯ä¸ªé…ç½®è¿­ä»£æ¬¡æ•°: {args.num_runs}")
    print(f"  æ‰¹æ¬¡å¤§å°: {args.batch_size}")

    # è·å–CPUä¿¡æ¯
    cpu_info = get_cpu_info()

    # æµ‹è¯•BERT
    bert_results = test_threading_configs(
        "bert", "BERT-Base",
        cpu_info,
        num_runs=args.num_runs,
        batch_size=args.batch_size
    )

    # æµ‹è¯•MobileNet
    mobilenet_results = test_threading_configs(
        "mobilenet", "MobileNetV2",
        cpu_info,
        num_runs=args.num_runs,
        batch_size=args.batch_size
    )

    # ä¿å­˜åŸå§‹ç»“æœ
    results_json = output_dir / "results.json"
    with open(results_json, 'w', encoding='utf-8') as f:
        json.dump({
            "cpu_info": cpu_info,
            "bert_results": bert_results,
            "mobilenet_results": mobilenet_results,
            "config": {
                "num_runs": args.num_runs,
                "batch_size": args.batch_size
            }
        }, f, indent=2, ensure_ascii=False)

    print(f"\nâœ“ åŸå§‹ç»“æœå·²ä¿å­˜: {results_json}")

    # ç”ŸæˆæŠ¥å‘Š
    report_path = output_dir / "threading_benchmark_report.md"
    generate_report(bert_results, mobilenet_results, cpu_info, report_path)

    # æ‰“å°æ€»ç»“
    print_section("âœ“ æµ‹è¯•å®Œæˆ!")

    bert_optimal = find_optimal_config(bert_results)
    mobilenet_optimal = find_optimal_config(mobilenet_results)

    bert_baseline = next((r for r in bert_results if r['intra_threads'] == 1), None)
    mobilenet_baseline = next((r for r in mobilenet_results if r['intra_threads'] == 1), None)

    if bert_optimal and bert_baseline:
        print(f"\nBERT-Baseæœ€ä¼˜é…ç½®: {bert_optimal['description']}")
        print(f"  åŠ é€Ÿæ¯”: {bert_optimal['throughput_samples_per_sec'] / bert_baseline['throughput_samples_per_sec']:.2f}x")
        print(f"  ååé‡: {bert_optimal['throughput_samples_per_sec']:.2f} samples/sec")

    if mobilenet_optimal and mobilenet_baseline:
        print(f"\nMobileNetV2æœ€ä¼˜é…ç½®: {mobilenet_optimal['description']}")
        print(f"  åŠ é€Ÿæ¯”: {mobilenet_optimal['throughput_samples_per_sec'] / mobilenet_baseline['throughput_samples_per_sec']:.2f}x")
        print(f"  ååé‡: {mobilenet_optimal['throughput_samples_per_sec']:.2f} samples/sec")

    print(f"\næŠ¥å‘Šæ–‡ä»¶: {report_path}")

if __name__ == "__main__":
    main()
