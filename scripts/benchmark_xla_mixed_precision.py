#!/usr/bin/env python3
"""
TensorFlow XLA + æ··åˆç²¾åº¦æ¨ç†æ€§èƒ½æµ‹è¯•

å¯¹æ¯”ä¸‰ç§æ¨ç†é…ç½®ï¼š
1. Baseline (FP32, æ— XLA)
2. XLAä¼˜åŒ– (FP32 + XLA)
3. XLA + æ··åˆç²¾åº¦ (FP16/FP32 + XLA)

è¦æ±‚ï¼šå‡†ç¡®ç‡ä¸‹é™å¹…åº¦ < 1%
"""

import os
import sys
import time
import json
import argparse
from pathlib import Path
import numpy as np
import tensorflow as tf
from tensorflow.keras import mixed_precision

def print_section(title):
    print("\n" + "=" * 70)
    print(title)
    print("=" * 70)

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
    print_section("ç¯å¢ƒæ£€æŸ¥")

    print(f"âœ“ TensorFlowç‰ˆæœ¬: {tf.__version__}")
    print(f"âœ“ NumPyç‰ˆæœ¬: {np.__version__}")

    # æ£€æŸ¥GPU
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        print(f"âœ“ æ£€æµ‹åˆ°GPU: {len(gpus)}ä¸ª")
        for gpu in gpus:
            print(f"  - {gpu.name}")
    else:
        print("âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUæµ‹è¯•")

    # æ£€æŸ¥XLAæ”¯æŒ
    print(f"âœ“ XLAç¼–è¯‘å™¨å¯ç”¨")

    return {
        "tensorflow": tf.__version__,
        "numpy": np.__version__,
        "gpu_available": len(gpus) > 0,
        "num_gpus": len(gpus)
    }


def create_test_model(model_type="cnn", input_shape=(28, 28, 1), num_classes=10):
    """åˆ›å»ºæµ‹è¯•æ¨¡å‹"""
    print_section(f"åˆ›å»ºæµ‹è¯•æ¨¡å‹: {model_type}")

    if model_type == "cnn":
        model = tf.keras.Sequential([
            tf.keras.layers.Input(shape=input_shape),
            tf.keras.layers.Conv2D(32, 3, activation='relu'),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Conv2D(64, 3, activation='relu'),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Conv2D(128, 3, activation='relu'),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(num_classes, activation='softmax')
        ], name="cnn_model")

    elif model_type == "resnet_like":
        inputs = tf.keras.layers.Input(shape=input_shape)

        # åˆå§‹å·ç§¯
        x = tf.keras.layers.Conv2D(64, 7, strides=2, padding='same')(inputs)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation('relu')(x)
        x = tf.keras.layers.MaxPooling2D(3, strides=2, padding='same')(x)

        # ResNetå—
        for filters in [64, 128, 256]:
            # æ®‹å·®å—
            shortcut = x

            x = tf.keras.layers.Conv2D(filters, 3, padding='same')(x)
            x = tf.keras.layers.BatchNormalization()(x)
            x = tf.keras.layers.Activation('relu')(x)

            x = tf.keras.layers.Conv2D(filters, 3, padding='same')(x)
            x = tf.keras.layers.BatchNormalization()(x)

            # è°ƒæ•´shortcutç»´åº¦
            if shortcut.shape[-1] != filters:
                shortcut = tf.keras.layers.Conv2D(filters, 1)(shortcut)
                shortcut = tf.keras.layers.BatchNormalization()(shortcut)

            x = tf.keras.layers.Add()([x, shortcut])
            x = tf.keras.layers.Activation('relu')(x)

        x = tf.keras.layers.GlobalAveragePooling2D()(x)
        x = tf.keras.layers.Dense(512, activation='relu')(x)
        x = tf.keras.layers.Dropout(0.5)(x)
        outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)

        model = tf.keras.Model(inputs=inputs, outputs=outputs, name="resnet_like")

    else:
        raise ValueError(f"Unknown model type: {model_type}")

    print(f"âœ“ æ¨¡å‹åˆ›å»ºå®Œæˆ")
    print(f"  å‚æ•°æ€»æ•°: {model.count_params():,}")

    return model


def prepare_test_data(input_shape, num_samples=1000, num_classes=10):
    """å‡†å¤‡æµ‹è¯•æ•°æ®"""
    print_section("å‡†å¤‡æµ‹è¯•æ•°æ®")

    # ç”Ÿæˆéšæœºæµ‹è¯•æ•°æ®
    X_test = np.random.randn(num_samples, *input_shape).astype(np.float32)
    y_test = np.random.randint(0, num_classes, num_samples)
    y_test_onehot = tf.keras.utils.to_categorical(y_test, num_classes)

    print(f"âœ“ æµ‹è¯•æ•°æ®å‡†å¤‡å®Œæˆ")
    print(f"  æ ·æœ¬æ•°: {num_samples}")
    print(f"  è¾“å…¥å½¢çŠ¶: {X_test.shape}")
    print(f"  ç±»åˆ«æ•°: {num_classes}")

    return X_test, y_test, y_test_onehot


def benchmark_baseline(model, X_test, y_test_onehot, num_runs=100, num_warmup=10):
    """
    Baselineæµ‹è¯• - FP32, æ— XLA
    """
    print_section("Baselineæµ‹è¯• (FP32, æ— XLA)")

    # ç¼–è¯‘æ¨¡å‹
    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    # çƒ­èº«
    print(f"çƒ­èº«: {num_warmup} iterations...")
    for i in range(num_warmup):
        _ = model.predict(X_test[:10], verbose=0)
        if (i + 1) % 5 == 0:
            print(f"  çƒ­èº«: {i+1}/{num_warmup}")

    # æ€§èƒ½æµ‹è¯•
    print(f"\næ€§èƒ½æµ‹è¯•: {num_runs} iterations...")
    batch_size = 32
    latencies = []

    for i in range(num_runs):
        start = time.perf_counter()
        _ = model.predict(X_test[:batch_size], verbose=0)
        latency = (time.perf_counter() - start) * 1000
        latencies.append(latency)

        if (i + 1) % 20 == 0:
            print(f"  æµ‹è¯•: {i+1}/{num_runs}")

    # å‡†ç¡®ç‡æµ‹è¯•
    print("\nå‡†ç¡®ç‡æµ‹è¯•...")
    loss, accuracy = model.evaluate(X_test, y_test_onehot, verbose=0)

    # ç»Ÿè®¡
    latencies = np.array(latencies)
    results = {
        "mean_ms": float(np.mean(latencies)),
        "median_ms": float(np.median(latencies)),
        "std_ms": float(np.std(latencies)),
        "p95_ms": float(np.percentile(latencies, 95)),
        "p99_ms": float(np.percentile(latencies, 99)),
        "throughput_samples_per_sec": float(batch_size * 1000.0 / np.mean(latencies)),
        "accuracy": float(accuracy),
        "loss": float(loss)
    }

    print(f"\nâœ“ Baselineæµ‹è¯•å®Œæˆ")
    print(f"  å¹³å‡å»¶è¿Ÿ: {results['mean_ms']:.2f} ms")
    print(f"  P95å»¶è¿Ÿ: {results['p95_ms']:.2f} ms")
    print(f"  ååé‡: {results['throughput_samples_per_sec']:.2f} samples/sec")
    print(f"  å‡†ç¡®ç‡: {results['accuracy']*100:.2f}%")

    return results


def benchmark_xla(model, X_test, y_test_onehot, num_runs=100, num_warmup=10):
    """
    XLAä¼˜åŒ–æµ‹è¯• - FP32 + XLA
    """
    print_section("XLAä¼˜åŒ–æµ‹è¯• (FP32 + XLA)")

    # å¯ç”¨XLA
    tf.config.optimizer.set_jit(True)
    print("âœ“ XLAç¼–è¯‘å™¨å·²å¯ç”¨")

    # ç¼–è¯‘æ¨¡å‹ï¼ˆä½¿ç”¨jit_compile=Trueï¼‰
    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy'],
        jit_compile=True  # å¯ç”¨XLAç¼–è¯‘
    )

    # çƒ­èº«ï¼ˆåŒ…æ‹¬XLAç¼–è¯‘æ—¶é—´ï¼‰
    print(f"\nçƒ­èº« (åŒ…æ‹¬XLAç¼–è¯‘): {num_warmup} iterations...")
    for i in range(num_warmup):
        _ = model.predict(X_test[:10], verbose=0)
        if (i + 1) % 5 == 0:
            print(f"  çƒ­èº«: {i+1}/{num_warmup}")

    # æ€§èƒ½æµ‹è¯•
    print(f"\næ€§èƒ½æµ‹è¯•: {num_runs} iterations...")
    batch_size = 32
    latencies = []

    for i in range(num_runs):
        start = time.perf_counter()
        _ = model.predict(X_test[:batch_size], verbose=0)
        latency = (time.perf_counter() - start) * 1000
        latencies.append(latency)

        if (i + 1) % 20 == 0:
            print(f"  æµ‹è¯•: {i+1}/{num_runs}")

    # å‡†ç¡®ç‡æµ‹è¯•
    print("\nå‡†ç¡®ç‡æµ‹è¯•...")
    loss, accuracy = model.evaluate(X_test, y_test_onehot, verbose=0)

    # ç»Ÿè®¡
    latencies = np.array(latencies)
    results = {
        "mean_ms": float(np.mean(latencies)),
        "median_ms": float(np.median(latencies)),
        "std_ms": float(np.std(latencies)),
        "p95_ms": float(np.percentile(latencies, 95)),
        "p99_ms": float(np.percentile(latencies, 99)),
        "throughput_samples_per_sec": float(batch_size * 1000.0 / np.mean(latencies)),
        "accuracy": float(accuracy),
        "loss": float(loss)
    }

    print(f"\nâœ“ XLAæµ‹è¯•å®Œæˆ")
    print(f"  å¹³å‡å»¶è¿Ÿ: {results['mean_ms']:.2f} ms")
    print(f"  P95å»¶è¿Ÿ: {results['p95_ms']:.2f} ms")
    print(f"  ååé‡: {results['throughput_samples_per_sec']:.2f} samples/sec")
    print(f"  å‡†ç¡®ç‡: {results['accuracy']*100:.2f}%")

    # ç¦ç”¨XLAï¼ˆä¸ºä¸‹ä¸€ä¸ªæµ‹è¯•å‡†å¤‡ï¼‰
    tf.config.optimizer.set_jit(False)

    return results


def benchmark_mixed_precision_xla(model, X_test, y_test_onehot, num_runs=100, num_warmup=10):
    """
    æ··åˆç²¾åº¦ + XLAæµ‹è¯• - FP16/FP32 + XLA
    """
    print_section("æ··åˆç²¾åº¦ + XLAæµ‹è¯• (FP16/FP32 + XLA)")

    # è®¾ç½®æ··åˆç²¾åº¦ç­–ç•¥
    policy = mixed_precision.Policy('mixed_float16')
    mixed_precision.set_global_policy(policy)
    print(f"âœ“ æ··åˆç²¾åº¦ç­–ç•¥å·²å¯ç”¨: {policy.name}")
    print(f"  è®¡ç®—dtype: {policy.compute_dtype}")
    print(f"  å˜é‡dtype: {policy.variable_dtype}")

    # é‡å»ºæ¨¡å‹ä»¥åº”ç”¨æ··åˆç²¾åº¦
    # æ··åˆç²¾åº¦ç­–ç•¥å·²ç»è®¾ç½®ï¼Œç›´æ¥ä½¿ç”¨åŸæ¨¡å‹å³å¯
    # Kerasä¼šè‡ªåŠ¨åº”ç”¨æ··åˆç²¾åº¦ç­–ç•¥åˆ°æ–°å±‚
    mixed_model = model

    # å¯ç”¨XLA
    tf.config.optimizer.set_jit(True)

    # ç¼–è¯‘æ¨¡å‹
    mixed_model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy'],
        jit_compile=True
    )

    # çƒ­èº«
    print(f"\nçƒ­èº« (åŒ…æ‹¬XLAç¼–è¯‘): {num_warmup} iterations...")
    for i in range(num_warmup):
        _ = mixed_model.predict(X_test[:10], verbose=0)
        if (i + 1) % 5 == 0:
            print(f"  çƒ­èº«: {i+1}/{num_warmup}")

    # æ€§èƒ½æµ‹è¯•
    print(f"\næ€§èƒ½æµ‹è¯•: {num_runs} iterations...")
    batch_size = 32
    latencies = []

    for i in range(num_runs):
        start = time.perf_counter()
        _ = mixed_model.predict(X_test[:batch_size], verbose=0)
        latency = (time.perf_counter() - start) * 1000
        latencies.append(latency)

        if (i + 1) % 20 == 0:
            print(f"  æµ‹è¯•: {i+1}/{num_runs}")

    # å‡†ç¡®ç‡æµ‹è¯•
    print("\nå‡†ç¡®ç‡æµ‹è¯•...")
    loss, accuracy = mixed_model.evaluate(X_test, y_test_onehot, verbose=0)

    # ç»Ÿè®¡
    latencies = np.array(latencies)
    results = {
        "mean_ms": float(np.mean(latencies)),
        "median_ms": float(np.median(latencies)),
        "std_ms": float(np.std(latencies)),
        "p95_ms": float(np.percentile(latencies, 95)),
        "p99_ms": float(np.percentile(latencies, 99)),
        "throughput_samples_per_sec": float(batch_size * 1000.0 / np.mean(latencies)),
        "accuracy": float(accuracy),
        "loss": float(loss)
    }

    print(f"\nâœ“ æ··åˆç²¾åº¦ + XLAæµ‹è¯•å®Œæˆ")
    print(f"  å¹³å‡å»¶è¿Ÿ: {results['mean_ms']:.2f} ms")
    print(f"  P95å»¶è¿Ÿ: {results['p95_ms']:.2f} ms")
    print(f"  ååé‡: {results['throughput_samples_per_sec']:.2f} samples/sec")
    print(f"  å‡†ç¡®ç‡: {results['accuracy']*100:.2f}%")

    # é‡ç½®ç­–ç•¥
    mixed_precision.set_global_policy('float32')
    tf.config.optimizer.set_jit(False)

    return results


def check_accuracy_constraint(baseline_acc, test_acc, max_drop_percent=1.0):
    """
    æ£€æŸ¥å‡†ç¡®ç‡çº¦æŸ

    Args:
        baseline_acc: baselineå‡†ç¡®ç‡
        test_acc: æµ‹è¯•å‡†ç¡®ç‡
        max_drop_percent: æœ€å¤§å…è®¸ä¸‹é™ç™¾åˆ†ç‚¹ï¼ˆé»˜è®¤1%ï¼‰

    Returns:
        (é€šè¿‡æ£€æŸ¥, å®é™…ä¸‹é™ç™¾åˆ†ç‚¹)
    """
    drop = (baseline_acc - test_acc) * 100  # è½¬æ¢ä¸ºç™¾åˆ†ç‚¹
    passed = drop <= max_drop_percent
    return passed, drop


def generate_report(env_info, model_info, baseline_results, xla_results,
                    mixed_results, output_dir, max_accuracy_drop=1.0):
    """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
    report_path = Path(output_dir) / "xla_mixed_precision_report.md"

    baseline_acc = baseline_results['accuracy']
    xla_acc = xla_results['accuracy']
    mixed_acc = mixed_results['accuracy']

    # æ£€æŸ¥å‡†ç¡®ç‡çº¦æŸ
    xla_passed, xla_drop = check_accuracy_constraint(baseline_acc, xla_acc, max_accuracy_drop)
    mixed_passed, mixed_drop = check_accuracy_constraint(baseline_acc, mixed_acc, max_accuracy_drop)

    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# TensorFlow XLA + æ··åˆç²¾åº¦æ€§èƒ½æµ‹è¯•æŠ¥å‘Š\n\n")
        f.write(f"**æµ‹è¯•æ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")

        f.write("## ç¯å¢ƒä¿¡æ¯\n\n")
        for key, value in env_info.items():
            f.write(f"- {key}: {value}\n")

        f.write("\n## æ¨¡å‹ä¿¡æ¯\n\n")
        for key, value in model_info.items():
            f.write(f"- {key}: {value}\n")

        f.write("\n## æ€§èƒ½å¯¹æ¯”\n\n")
        f.write("| é…ç½® | å¹³å‡å»¶è¿Ÿ | P95å»¶è¿Ÿ | ååé‡ | åŠ é€Ÿæ¯” |\n")
        f.write("|------|----------|---------|--------|--------|\n")

        baseline_lat = baseline_results['mean_ms']
        xla_lat = xla_results['mean_ms']
        mixed_lat = mixed_results['mean_ms']

        f.write(f"| Baseline (FP32) | {baseline_lat:.2f} ms | ")
        f.write(f"{baseline_results['p95_ms']:.2f} ms | ")
        f.write(f"{baseline_results['throughput_samples_per_sec']:.2f} samples/s | 1.00x |\n")

        xla_speedup = baseline_lat / xla_lat
        f.write(f"| XLA (FP32) | {xla_lat:.2f} ms | ")
        f.write(f"{xla_results['p95_ms']:.2f} ms | ")
        f.write(f"{xla_results['throughput_samples_per_sec']:.2f} samples/s | ")
        f.write(f"{xla_speedup:.2f}x {'ğŸš€' if xla_speedup > 1.1 else ''} |\n")

        mixed_speedup = baseline_lat / mixed_lat
        f.write(f"| XLA + Mixed (FP16) | {mixed_lat:.2f} ms | ")
        f.write(f"{mixed_results['p95_ms']:.2f} ms | ")
        f.write(f"{mixed_results['throughput_samples_per_sec']:.2f} samples/s | ")
        f.write(f"{mixed_speedup:.2f}x {'ğŸš€' if mixed_speedup > 1.1 else ''} |\n")

        f.write("\n## å‡†ç¡®ç‡å¯¹æ¯”\n\n")
        f.write("| é…ç½® | å‡†ç¡®ç‡ | vs Baseline | çŠ¶æ€ |\n")
        f.write("|------|--------|-------------|------|\n")

        f.write(f"| Baseline (FP32) | {baseline_acc*100:.2f}% | - | âœ… |\n")

        f.write(f"| XLA (FP32) | {xla_acc*100:.2f}% | ")
        if xla_drop >= 0:
            f.write(f"-{xla_drop:.2f}% | ")
        else:
            f.write(f"+{abs(xla_drop):.2f}% | ")
        f.write(f"{'âœ…' if xla_passed else 'âŒ'} ")
        f.write(f"{'é€šè¿‡' if xla_passed else f'è¶…æ ‡(>{max_accuracy_drop}%)'} |\n")

        f.write(f"| XLA + Mixed (FP16) | {mixed_acc*100:.2f}% | ")
        if mixed_drop >= 0:
            f.write(f"-{mixed_drop:.2f}% | ")
        else:
            f.write(f"+{abs(mixed_drop):.2f}% | ")
        f.write(f"{'âœ…' if mixed_passed else 'âŒ'} ")
        f.write(f"{'é€šè¿‡' if mixed_passed else f'è¶…æ ‡(>{max_accuracy_drop}%)'} |\n")

        f.write(f"\n**å‡†ç¡®ç‡çº¦æŸ**: å‡†ç¡®ç‡ä¸‹é™ â‰¤ {max_accuracy_drop}%\n\n")

        f.write("## æ€»ç»“\n\n")

        f.write("### æ€§èƒ½æå‡\n\n")
        f.write(f"- **XLAä¼˜åŒ–**: {xla_speedup:.2f}x åŠ é€Ÿ\n")
        f.write(f"- **XLA + æ··åˆç²¾åº¦**: {mixed_speedup:.2f}x åŠ é€Ÿ\n")
        f.write(f"- **æ··åˆç²¾åº¦é¢å¤–å¢ç›Š**: {xla_lat/mixed_lat:.2f}x (ç›¸å¯¹äºXLA FP32)\n")

        f.write("\n### å‡†ç¡®ç‡å½±å“\n\n")
        f.write(f"- **XLAä¼˜åŒ–**: {abs(xla_drop):.2f}% {'ä¸‹é™' if xla_drop > 0 else 'æå‡'}\n")
        f.write(f"- **XLA + æ··åˆç²¾åº¦**: {abs(mixed_drop):.2f}% {'ä¸‹é™' if mixed_drop > 0 else 'æå‡'}\n")

        f.write("\n### æ¨èé…ç½®\n\n")

        if mixed_passed and mixed_speedup > xla_speedup:
            f.write("âœ… **æ¨èä½¿ç”¨ XLA + æ··åˆç²¾åº¦**\n\n")
            f.write(f"- æ€§èƒ½æå‡æœ€å¤§: {mixed_speedup:.2f}x\n")
            f.write(f"- å‡†ç¡®ç‡ä¸‹é™å¯æ¥å—: {abs(mixed_drop):.2f}%\n")
            f.write(f"- æ»¡è¶³ <{max_accuracy_drop}% çº¦æŸæ¡ä»¶\n")
        elif xla_passed:
            f.write("âœ… **æ¨èä½¿ç”¨ XLAä¼˜åŒ–**\n\n")
            f.write(f"- æ€§èƒ½æå‡: {xla_speedup:.2f}x\n")
            f.write(f"- å‡†ç¡®ç‡å‡ ä¹æ— æŸå¤±: {abs(xla_drop):.2f}%\n")
            if not mixed_passed:
                f.write(f"- æ··åˆç²¾åº¦å‡†ç¡®ç‡ä¸‹é™è¶…æ ‡: {abs(mixed_drop):.2f}% > {max_accuracy_drop}%\n")
        else:
            f.write("âš ï¸ **å»ºè®®ç»§ç»­ä½¿ç”¨Baseline**\n\n")
            f.write(f"- XLAä¼˜åŒ–å‡†ç¡®ç‡ä¸‹é™: {abs(xla_drop):.2f}%\n")
            f.write(f"- æ··åˆç²¾åº¦å‡†ç¡®ç‡ä¸‹é™: {abs(mixed_drop):.2f}%\n")
            f.write(f"- å‡è¶…è¿‡çº¦æŸæ¡ä»¶ ({max_accuracy_drop}%)\n")

    print(f"\nâœ“ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    return str(report_path)


def main():
    parser = argparse.ArgumentParser(description="TensorFlow XLA + æ··åˆç²¾åº¦æ€§èƒ½æµ‹è¯•")
    parser.add_argument("--model-type", default="cnn", choices=["cnn", "resnet_like"],
                       help="æ¨¡å‹ç±»å‹")
    parser.add_argument("--output-dir", default="results/xla_mixed_precision",
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--num-runs", type=int, default=100,
                       help="æ€§èƒ½æµ‹è¯•è¿­ä»£æ¬¡æ•°")
    parser.add_argument("--num-warmup", type=int, default=10,
                       help="çƒ­èº«è¿­ä»£æ¬¡æ•°")
    parser.add_argument("--num-samples", type=int, default=1000,
                       help="æµ‹è¯•æ ·æœ¬æ•°")
    parser.add_argument("--max-accuracy-drop", type=float, default=1.0,
                       help="æœ€å¤§å…è®¸å‡†ç¡®ç‡ä¸‹é™ï¼ˆç™¾åˆ†ç‚¹ï¼‰")
    args = parser.parse_args()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ç¯å¢ƒæ£€æŸ¥
    env_info = check_environment()

    # åˆ›å»ºæ¨¡å‹
    input_shape = (28, 28, 1)
    num_classes = 10
    model = create_test_model(args.model_type, input_shape, num_classes)

    model_info = {
        "æ¨¡å‹ç±»å‹": args.model_type,
        "è¾“å…¥å½¢çŠ¶": str(input_shape),
        "ç±»åˆ«æ•°": num_classes,
        "å‚æ•°æ€»æ•°": f"{model.count_params():,}"
    }

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    X_test, y_test, y_test_onehot = prepare_test_data(
        input_shape, args.num_samples, num_classes
    )

    # æµ‹è¯•1: Baseline (FP32, æ— XLA)
    baseline_results = benchmark_baseline(
        model, X_test, y_test_onehot, args.num_runs, args.num_warmup
    )

    # æµ‹è¯•2: XLA (FP32 + XLA)
    xla_results = benchmark_xla(
        model, X_test, y_test_onehot, args.num_runs, args.num_warmup
    )

    # æµ‹è¯•3: Mixed Precision + XLA (FP16/FP32 + XLA)
    mixed_results = benchmark_mixed_precision_xla(
        model, X_test, y_test_onehot, args.num_runs, args.num_warmup
    )

    # ä¿å­˜ç»“æœ
    results = {
        "environment": env_info,
        "model": model_info,
        "baseline": baseline_results,
        "xla": xla_results,
        "mixed_precision_xla": mixed_results,
        "config": {
            "num_runs": args.num_runs,
            "num_warmup": args.num_warmup,
            "num_samples": args.num_samples,
            "max_accuracy_drop": args.max_accuracy_drop
        }
    }

    results_json = output_dir / "results.json"
    with open(results_json, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    print(f"\nâœ“ ç»“æœå·²ä¿å­˜: {results_json}")

    # ç”ŸæˆæŠ¥å‘Š
    report_path = generate_report(
        env_info, model_info, baseline_results, xla_results,
        mixed_results, output_dir, args.max_accuracy_drop
    )

    # æ‰“å°æ€»ç»“
    print_section("âœ“ æµ‹è¯•å®Œæˆ!")

    baseline_acc = baseline_results['accuracy']
    xla_acc = xla_results['accuracy']
    mixed_acc = mixed_results['accuracy']

    baseline_lat = baseline_results['mean_ms']
    xla_lat = xla_results['mean_ms']
    mixed_lat = mixed_results['mean_ms']

    print(f"\næ€§èƒ½æå‡:")
    print(f"  XLAä¼˜åŒ–: {baseline_lat/xla_lat:.2f}x")
    print(f"  XLA + æ··åˆç²¾åº¦: {baseline_lat/mixed_lat:.2f}x")

    print(f"\nå‡†ç¡®ç‡å¯¹æ¯”:")
    print(f"  Baseline: {baseline_acc*100:.2f}%")
    print(f"  XLA: {xla_acc*100:.2f}% ({(baseline_acc-xla_acc)*100:+.2f}%)")
    print(f"  XLA + Mixed: {mixed_acc*100:.2f}% ({(baseline_acc-mixed_acc)*100:+.2f}%)")

    # æ£€æŸ¥çº¦æŸ
    xla_passed, xla_drop = check_accuracy_constraint(baseline_acc, xla_acc, args.max_accuracy_drop)
    mixed_passed, mixed_drop = check_accuracy_constraint(baseline_acc, mixed_acc, args.max_accuracy_drop)

    print(f"\nå‡†ç¡®ç‡çº¦æŸæ£€æŸ¥ (â‰¤{args.max_accuracy_drop}%):")
    print(f"  XLA: {'âœ… é€šè¿‡' if xla_passed else 'âŒ å¤±è´¥'} ({abs(xla_drop):.2f}%)")
    print(f"  XLA + Mixed: {'âœ… é€šè¿‡' if mixed_passed else 'âŒ å¤±è´¥'} ({abs(mixed_drop):.2f}%)")

    print(f"\nç»“æœæ–‡ä»¶:")
    print(f"  - JSONç»“æœ: {results_json}")
    print(f"  - å¯¹æ¯”æŠ¥å‘Š: {report_path}")


if __name__ == "__main__":
    main()
