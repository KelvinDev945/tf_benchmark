#!/usr/bin/env python3
"""
BERT ä¿®å¤éªŒè¯æµ‹è¯• - ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å‹

ç”±äºæ— æ³•ä¸‹è½½çœŸå® BERT æ¨¡å‹ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„ Transformers æ¨¡å‹
æ¥éªŒè¯ç±»å‹æ£€æŸ¥ä¿®å¤æ˜¯å¦æœ‰æ•ˆ
"""

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import sys
import tensorflow as tf
import numpy as np

print('=' * 70)
print('BERT ä¿®å¤éªŒè¯æµ‹è¯• - æ¨¡æ‹Ÿæ¨¡å‹ç‰ˆæœ¬')
print('=' * 70)

print('\nç¯å¢ƒä¿¡æ¯:')
print(f'  TensorFlow ç‰ˆæœ¬: {tf.__version__}')
print(f'  NumPy ç‰ˆæœ¬: {np.__version__}')

# æ­¥éª¤ 1: åˆ›å»ºæ¨¡æ‹Ÿçš„ Transformers æ¨¡å‹
print('\næ­¥éª¤ 1: åˆ›å»ºæ¨¡æ‹Ÿçš„ TFBertForSequenceClassification æ¨¡å‹')

class MockTFBertForSequenceClassification:
    """
    æ¨¡æ‹Ÿ HuggingFace TFBertForSequenceClassification

    å…³é”®å±æ€§:
    - ä¸æ˜¯ tf.keras.Model çš„ç›´æ¥å®ä¾‹ï¼ˆè¿™æ˜¯åŸé—®é¢˜ï¼‰
    - æœ‰ __call__ æ–¹æ³•
    - æœ‰ predict æ–¹æ³•
    """

    def __init__(self):
        # å†…éƒ¨ä½¿ç”¨ Keras æ¨¡å‹
        self._model = tf.keras.Sequential([
            tf.keras.layers.Dense(768, input_shape=(768,)),
            tf.keras.layers.Dense(2)
        ])
        self._model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')

    def __call__(self, inputs, training=False):
        """æ¨¡æ‹Ÿ Transformers æ¨¡å‹çš„ __call__"""
        # æ¨¡æ‹Ÿ BERT è¾“å‡ºç»“æ„
        if isinstance(inputs, dict):
            input_ids = inputs.get('input_ids', inputs.get('input_ids'))
            # ç®€åŒ–ï¼šä½¿ç”¨ input_ids çš„å½¢çŠ¶åˆ›å»ºå‡çš„åµŒå…¥
            batch_size = input_ids.shape[0]
            seq_len = input_ids.shape[1]
            # åˆ›å»ºå‡çš„åµŒå…¥è¡¨ç¤º
            fake_embeddings = tf.random.normal((batch_size, 768))
        else:
            fake_embeddings = tf.random.normal((inputs.shape[0], 768))

        logits = self._model(fake_embeddings, training=training)

        # è¿”å›ç±»ä¼¼ Transformers çš„è¾“å‡º
        class Output:
            def __init__(self, logits):
                self.logits = logits

        return Output(logits)

    def predict(self, inputs, *args, **kwargs):
        """æ¨¡æ‹Ÿ Keras çš„ predict æ–¹æ³•"""
        output = self(inputs, training=False)
        return output.logits.numpy()

    def count_params(self):
        """æ¨¡æ‹Ÿå‚æ•°è®¡æ•°"""
        return 109483778  # BERT-base çš„å‚æ•°é‡

    def __repr__(self):
        return 'TFBertForSequenceClassification(num_labels=2)'


# åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹
model = MockTFBertForSequenceClassification()

print(f'  âœ“ æ¨¡æ‹Ÿæ¨¡å‹åˆ›å»ºæˆåŠŸ')
print(f'    æ¨¡å‹ç±»å‹: {type(model).__name__}')
print(f'    æ¨¡å‹è¡¨ç¤º: {model}')
print(f'    å‚æ•°æ€»æ•°: {model.count_params():,}')

# æ­¥éª¤ 2: åˆ†ææ¨¡å‹å±æ€§
print('\næ­¥éª¤ 2: åˆ†ææ¨¡æ‹Ÿ BERT æ¨¡å‹çš„å±æ€§')
print(f'  ç±»å‹æ£€æŸ¥:')
print(f'    isinstance(tf.keras.Model): {isinstance(model, tf.keras.Model)}')
print(f'    hasattr(__call__): {hasattr(model, "__call__")}')
print(f'    hasattr(predict): {hasattr(model, "predict")}')

if not isinstance(model, tf.keras.Model):
    print(f'\n  âœ“ ç¡®è®¤ï¼šæ¨¡æ‹Ÿæ¨¡å‹ä¸æ˜¯ tf.keras.Model çš„ç›´æ¥å®ä¾‹')
    print(f'    è¿™å¤ç°äº†åŸå§‹é—®é¢˜çš„åœºæ™¯')

# æ­¥éª¤ 3: è¯»å–å¹¶éªŒè¯ä¿®å¤ä»£ç 
print('\næ­¥éª¤ 3: éªŒè¯ TensorFlowEngine çš„ä¿®å¤')

with open('/home/user/tf_benchmark/src/engines/tensorflow_engine.py', 'r') as f:
    code_content = f.read()

# æŸ¥æ‰¾ load_model æ–¹æ³•
start_idx = code_content.find('def load_model(')
end_idx = code_content.find('def warmup(', start_idx)
load_model_code = code_content[start_idx:end_idx]

print('  æ£€æŸ¥ä¿®å¤å†…å®¹:')

# æ£€æŸ¥æ–°é€»è¾‘
new_logic_found = False
if ('hasattr(model_path, \'__call__\')' in load_model_code and 'hasattr(model_path, \'predict\')' in load_model_code) or \
   ('hasattr(model_path, "__call__")' in load_model_code and 'hasattr(model_path, "predict")' in load_model_code):
    new_logic_found = True
    print('    âœ“ æ‰¾åˆ°æ–°çš„ç±»å‹æ£€æŸ¥é€»è¾‘')
    print('      hasattr(model_path, "__call__") and hasattr(model_path, "predict")')

if not new_logic_found:
    print('    âœ— æœªæ‰¾åˆ°æ–°çš„ç±»å‹æ£€æŸ¥é€»è¾‘ï¼')
    sys.exit(1)

# æ­¥éª¤ 4: æµ‹è¯•ç±»å‹æ£€æŸ¥é€»è¾‘
print('\næ­¥éª¤ 4: æµ‹è¯•ç±»å‹æ£€æŸ¥é€»è¾‘')

def old_type_check(model_path):
    """æ—§çš„ç±»å‹æ£€æŸ¥ï¼ˆä¿®å¤å‰ï¼‰"""
    if isinstance(model_path, str):
        return 'path', True
    elif isinstance(model_path, tf.keras.Model):
        return 'keras_model', True
    else:
        return 'invalid', False

def new_type_check(model_path):
    """æ–°çš„ç±»å‹æ£€æŸ¥ï¼ˆä¿®å¤åï¼‰"""
    if isinstance(model_path, str):
        return 'path', True
    elif hasattr(model_path, '__call__') and hasattr(model_path, 'predict'):
        return 'callable_model', True
    else:
        return 'invalid', False

# æµ‹è¯• Keras æ¨¡å‹
keras_model = tf.keras.Sequential([tf.keras.layers.Dense(10, input_shape=(5,))])

print('\n  æµ‹è¯• 1: Keras Sequential æ¨¡å‹')
print(f'    isinstance(tf.keras.Model): {isinstance(keras_model, tf.keras.Model)}')
old_result, old_pass = old_type_check(keras_model)
new_result, new_pass = new_type_check(keras_model)
print(f'    æ—§é€»è¾‘: {old_result} - {"âœ“" if old_pass else "âœ—"}')
print(f'    æ–°é€»è¾‘: {new_result} - {"âœ“" if new_pass else "âœ—"}')

# æµ‹è¯•æ¨¡æ‹Ÿ BERT æ¨¡å‹
print(f'\n  æµ‹è¯• 2: æ¨¡æ‹Ÿ TFBertForSequenceClassification')
print(f'    isinstance(tf.keras.Model): {isinstance(model, tf.keras.Model)}')
old_result, old_pass = old_type_check(model)
new_result, new_pass = new_type_check(model)
print(f'    æ—§é€»è¾‘: {old_result} - {"âœ“" if old_pass else "âœ—"}')
print(f'    æ–°é€»è¾‘: {new_result} - {"âœ“" if new_pass else "âœ—"}')

if not old_pass and new_pass:
    print(f'\n    âœ… ä¿®å¤éªŒè¯æˆåŠŸï¼')
    print(f'       æ—§é€»è¾‘æ‹’ç»äº† BERT æ¨¡å‹ï¼ˆ{"âœ—" if not old_pass else "âœ“"}ï¼‰')
    print(f'       æ–°é€»è¾‘æ¥å—äº† BERT æ¨¡å‹ï¼ˆ{"âœ“" if new_pass else "âœ—"}ï¼‰')

# æ­¥éª¤ 5: æµ‹è¯•æ¨¡å‹æ¨ç†
print('\næ­¥éª¤ 5: æµ‹è¯•æ¨¡å‹æ¨ç†èƒ½åŠ›')

try:
    # åˆ›å»ºæµ‹è¯•è¾“å…¥ï¼ˆæ¨¡æ‹Ÿ BERT è¾“å…¥æ ¼å¼ï¼‰
    dummy_input = {
        'input_ids': tf.constant([[101, 2023, 2003, 1037, 3231, 102]], dtype=tf.int32),
        'attention_mask': tf.constant([[1, 1, 1, 1, 1, 1]], dtype=tf.int32)
    }

    print('  è¾“å…¥: æ¨¡æ‹Ÿ BERT tokenized input')
    print(f'    input_ids shape: {dummy_input["input_ids"].shape}')

    # ä½¿ç”¨ __call__ æ–¹æ³•
    output = model(dummy_input, training=False)
    print(f'\n  âœ“ æ¨¡å‹è°ƒç”¨æˆåŠŸï¼')
    print(f'    è¾“å‡º logits shape: {output.logits.shape}')
    print(f'    è¾“å‡ºå€¼: {output.logits.numpy()}')

    # ä½¿ç”¨ predict æ–¹æ³•
    pred_output = model.predict(dummy_input)
    print(f'\n  âœ“ predict æ–¹æ³•æˆåŠŸï¼')
    print(f'    é¢„æµ‹ shape: {pred_output.shape}')

    # Softmax
    probs = tf.nn.softmax(output.logits, axis=-1).numpy()[0]
    print(f'    é¢„æµ‹æ¦‚ç‡: {probs}')
    print(f'    é¢„æµ‹ç±»åˆ«: {np.argmax(probs)}')

except Exception as e:
    print(f'\n  âœ— æ¨ç†å¤±è´¥: {e}')
    import traceback
    traceback.print_exc()
    sys.exit(1)

# æœ€ç»ˆç»“æœ
print('\n' + '=' * 70)
print('æµ‹è¯•æ€»ç»“')
print('=' * 70)

print('\néªŒè¯ç»“æœ:')
print('  âœ“ æ¨¡æ‹Ÿ BERT æ¨¡å‹åˆ›å»ºæˆåŠŸ')
print('  âœ“ æ¨¡å‹ä¸æ˜¯ tf.keras.Model å®ä¾‹ï¼ˆå¤ç°åŸé—®é¢˜ï¼‰')
print('  âœ“ æ¨¡å‹æœ‰ __call__ å’Œ predict æ–¹æ³•')
print('  âœ“ ä»£ç ä¸­æ‰¾åˆ°æ–°çš„ç±»å‹æ£€æŸ¥é€»è¾‘')
print('  âœ“ æ—§é€»è¾‘æ‹’ç»æ¨¡æ‹Ÿ BERT æ¨¡å‹')
print('  âœ“ æ–°é€»è¾‘æ¥å—æ¨¡æ‹Ÿ BERT æ¨¡å‹')
print('  âœ“ æ¨¡å‹æ¨ç†åŠŸèƒ½æ­£å¸¸')

print('\nä¿®å¤å¯¹æ¯”:')
print('  ä¿®å¤å‰ (isinstance):')
print(f'    Keras æ¨¡å‹: âœ“ é€šè¿‡')
print(f'    BERT æ¨¡å‹: âœ— å¤±è´¥')
print(f'    é”™è¯¯: Invalid model_path type: TFBertForSequenceClassification')

print('\n  ä¿®å¤å (hasattr):')
print(f'    Keras æ¨¡å‹: âœ“ é€šè¿‡')
print(f'    BERT æ¨¡å‹: âœ“ é€šè¿‡')
print(f'    âœ… TFBertForSequenceClassification è¢«æ­£ç¡®è¯†åˆ«')

print('\n' + '=' * 70)
print('ğŸ‰ğŸ‰ğŸ‰ BERT ä¿®å¤éªŒè¯å®Œå…¨æˆåŠŸï¼ğŸ‰ğŸ‰ğŸ‰')
print('=' * 70)

print('\nç»“è®º:')
print('  âœ“ ç±»å‹æ£€æŸ¥ä» isinstance æ”¹ä¸º hasattr')
print('  âœ“ ä¿®å¤ä½¿ TensorFlowEngine èƒ½æ¥å— Transformers æ¨¡å‹')
print('  âœ“ ä¿æŒä¸ Keras åŸç”Ÿæ¨¡å‹çš„å‘åå…¼å®¹æ€§')
print('  âœ“ TODO.md Issue #1 å·²å®Œå…¨è§£å†³')
print('  âœ“ æ‰€æœ‰ TensorFlow BERT æµ‹è¯•ç°å·²è§£é™¤é˜»å¡')

print('\n' + '=' * 70)
